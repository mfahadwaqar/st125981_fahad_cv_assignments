{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd2827b1",
   "metadata": {},
   "source": [
    "## CV Assignment 2 - Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad5857",
   "metadata": {},
   "source": [
    "Name: Muhammad Fahad Waqar<br>\n",
    "Student No: st125981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d1169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98ef3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENCV_TRACKERS = {\n",
    "    \"csrt\": cv2.legacy.TrackerCSRT_create,\n",
    "    \"kcf\": cv2.legacy.TrackerKCF_create,\n",
    "    \"mosse\": cv2.legacy.TrackerMOSSE_create\n",
    "}\n",
    "\n",
    "TRACKERS_TO_TEST = [\"kcf\", \"csrt\"]\n",
    "\n",
    "# VIDEO_FILENAME = \"videos/2103099-uhd_3840_2160_30fps.mp4\" \n",
    "VIDEO_FILENAME = \"videos/853960-hd_1920_1080_25fps.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47515e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tracking_session(tracker_name, video_path):\n",
    "    # Get the tracker constructor from our dictionary\n",
    "    tracker_constructor = OPENCV_TRACKERS.get(tracker_name)\n",
    "    if not tracker_constructor:\n",
    "        print(f\"Error: Tracker '{tracker_name}' not found in OpenCV version.\")\n",
    "        print(\"Please ensure you have 'opencv-contrib-python' installed.\")\n",
    "        return [], 0\n",
    "    \n",
    "    try:\n",
    "        tracker = tracker_constructor()\n",
    "    except cv2.error as e:\n",
    "        print(f\"Failed to create tracker '{tracker_name}'.\")\n",
    "        print(\"Error: {e}\")\n",
    "        print(\"Please ensure you have 'opencv-contrib-python' installed correctly.\")\n",
    "        return [], 0\n",
    "    \n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        print(\"Please check the path in VIDEO_FILENAME.\")\n",
    "        return [], 0\n",
    "\n",
    "    # Read the first frame\n",
    "    ok, first_frame = cap.read()\n",
    "    if not ok:\n",
    "        print(\"Error: Could not read first frame.\")\n",
    "        cap.release() # Add release\n",
    "        return 0, 0, 0\n",
    "\n",
    "    # Select ROI (Region of Interest)\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(f\"Running Tracker: {tracker_name.upper()}\")\n",
    "    print(\"A window will pop up. \")\n",
    "    print(\"1. Use your mouse to draw a box around the object you want to track.\")\n",
    "    print(\"2. Press ENTER or SPACE to confirm.\")\n",
    "    print(\"3. Press 'c' to cancel selection.\")\n",
    "    \n",
    "    # FIX for High-Resolution Screens\n",
    "    max_display_width = 1280\n",
    "    orig_h, orig_w = first_frame.shape[:2]\n",
    "    \n",
    "    # Only resize if the original width is larger than our max display width\n",
    "    if orig_w > max_display_width:\n",
    "        scale_factor = max_display_width / orig_w\n",
    "        display_w = int(orig_w * scale_factor)\n",
    "        display_h = int(orig_h * scale_factor)\n",
    "        display_frame = cv2.resize(first_frame, (display_w, display_h))\n",
    "    else:\n",
    "        # If it's already small enough, just use the original\n",
    "        display_frame = first_frame\n",
    "        scale_factor = 1.0\n",
    "    \n",
    "    # selectROI returns (x, y, w, h)\n",
    "    init_bbox_scaled = cv2.selectROI(\"Select Object to Track\", display_frame, fromCenter=False, showCrosshair=True)\n",
    "    cv2.destroyWindow(\"Select Object to Track\")\n",
    "    \n",
    "    if init_bbox_scaled == (0, 0, 0, 0):\n",
    "        print(\"No bounding box selected. Aborting session.\")\n",
    "        cap.release()\n",
    "        return 0, 0, 0\n",
    "\n",
    "    # Scale the bounding box back to the original frame's dimensions\n",
    "    inv_scale_factor = 1.0 / scale_factor\n",
    "    init_bbox = tuple([int(v * inv_scale_factor) for v in init_bbox_scaled])\n",
    "\n",
    "    # Initialize Tracker\n",
    "    tracker.init(first_frame, init_bbox)\n",
    "    \n",
    "    # Setup Output Video\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    output_filename = f\"output_{tracker_name}.mp4\"\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    # Using 'mp4v' for .mp4 files\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_filename, fourcc, video_fps, (frame_width, frame_height))\n",
    "\n",
    "    print(f\"Tracking started. Output will be saved to '{output_filename}'\")\n",
    "    \n",
    "    fps_list = []\n",
    "    failure_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            # End of video\n",
    "            break\n",
    "            \n",
    "        # Update Tracker\n",
    "        start_time = time.time()\n",
    "        success, bbox = tracker.update(frame)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate FPS\n",
    "        fps = 1.0 / (end_time - start_time)\n",
    "        fps_list.append(fps)\n",
    "        \n",
    "        # Draw Results on Frame\n",
    "        if success:\n",
    "            # Tracking success\n",
    "            (x, y, w, h) = [int(v) for v in bbox]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2, 1) # Green\n",
    "            status_text = \"STATUS: Tracking\"\n",
    "            status_color = (0, 255, 0)\n",
    "        else:\n",
    "            # Tracking failure\n",
    "            failure_count += 1\n",
    "            status_text = \"STATUS: Tracking Failure\"\n",
    "            status_color = (0, 0, 255) # Red\n",
    "\n",
    "        # Add info text to the frame\n",
    "        info_text = f\"Tracker: {tracker_name.upper()} | FPS: {int(fps)}\"\n",
    "        # cv2.putText(frame, info_text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2) # Black outline\n",
    "        # cv2.putText(frame, info_text, (11, 21), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1) # White text\n",
    "        \n",
    "        # cv2.putText(frame, status_text, (10, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "        # cv2.putText(frame, status_text, (11, 46), cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 1)\n",
    "\n",
    "        font_scale = 1.2\n",
    "        font_thickness_outline = 3\n",
    "        font_thickness_text = 2\n",
    "        \n",
    "        info_pos = (20, 40)  # (x, y) for top line\n",
    "        status_pos = (20, 80) # (x, y) for bottom line\n",
    "\n",
    "        cv2.putText(frame, info_text, info_pos, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), font_thickness_outline) # Black outline\n",
    "        cv2.putText(frame, info_text, (info_pos[0]+1, info_pos[1]+1), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), font_thickness_text) # White text\n",
    "        \n",
    "        cv2.putText(frame, status_text, status_pos, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), font_thickness_outline)\n",
    "        cv2.putText(frame, status_text, (status_pos[0]+1, status_pos[1]+1), cv2.FONT_HERSHEY_SIMPLEX, font_scale, status_color, font_thickness_text)\n",
    "\n",
    "        # Write Frame to Output Video\n",
    "        out.write(frame)\n",
    "        \n",
    "        # Display Resized Frame\n",
    "        # Resize the frame for display to prevent cropping on large videos\n",
    "        if orig_w > max_display_width:\n",
    "            # We use the display_w and display_h calculated during ROI selection\n",
    "            display_frame_live = cv2.resize(frame, (display_w, display_h))\n",
    "        else:\n",
    "            display_frame_live = frame\n",
    "            \n",
    "        # Display the resized frame\n",
    "        cv2.imshow(f\"Tracking with {tracker_name.upper()}\", display_frame_live)\n",
    "\n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Cleanup\n",
    "    print(f\"Tracking session for {tracker_name.upper()} finished.\")\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Calculate average FPS and return\n",
    "    avg_fps = np.mean(fps_list) if fps_list else 0\n",
    "    return avg_fps, failure_count, len(fps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42038a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Running Tracker: KCF\n",
      "A window will pop up. \n",
      "1. Use your mouse to draw a box around the object you want to track.\n",
      "2. Press ENTER or SPACE to confirm.\n",
      "3. Press 'c' to cancel selection.\n",
      "Tracking started. Output will be saved to 'output_kcf.mp4'\n",
      "Tracking session for KCF finished.\n",
      "\n",
      "--------------------------------------------------\n",
      "Running Tracker: CSRT\n",
      "A window will pop up. \n",
      "1. Use your mouse to draw a box around the object you want to track.\n",
      "2. Press ENTER or SPACE to confirm.\n",
      "3. Press 'c' to cancel selection.\n",
      "Tracking started. Output will be saved to 'output_csrt.mp4'\n",
      "Tracking session for CSRT finished.\n",
      "Metric          | KCF                  | CSRT                 |\n",
      "--------------- | -------------------- | -------------------- |\n",
      "Avg. FPS        | 207.19               | 31.62                |\n",
      "Total Failures  | 125                  | 0                    |\n",
      "Success Rate    | 52.83              % | 100.00             % |\n"
     ]
    }
   ],
   "source": [
    "# Check if video exists\n",
    "if not os.path.exists(VIDEO_FILENAME) or os.path.getsize(VIDEO_FILENAME) == 0:\n",
    "    print(f\"Error: Sample video '{VIDEO_FILENAME}' is missing or empty.\")\n",
    "    print(\"Please make sure the VIDEO_FILENAME variable in Cell [2] is set to the correct path.\")\n",
    "else:\n",
    "    # Run tracking sessions for each tracker\n",
    "    results = {}\n",
    "    total_frames = 0\n",
    "    \n",
    "    for tracker_name in TRACKERS_TO_TEST:\n",
    "        avg_fps, failures, num_frames = run_tracking_session(tracker_name, VIDEO_FILENAME)\n",
    "        \n",
    "        if num_frames > 0:\n",
    "            total_frames = num_frames\n",
    "            results[tracker_name] = {\n",
    "                \"avg_fps\": avg_fps,\n",
    "                \"failures\": failures,\n",
    "                \"success_rate\": 100 * (num_frames - failures) / num_frames\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Session for {tracker_name} was cancelled or failed to start.\")\n",
    "\n",
    "    # Print results\n",
    "    if results:\n",
    "        # Print a formatted table\n",
    "        print(f\"{'Metric':<15} | {'KCF':<20} | {'CSRT':<20} |\")\n",
    "        print(f\"{'-'*15} | {'-'*20} | {'-'*20} |\")\n",
    "        \n",
    "        kcf_fps = results.get(\"kcf\", {}).get(\"avg_fps\", 0)\n",
    "        csrt_fps = results.get(\"csrt\", {}).get(\"avg_fps\", 0)\n",
    "        print(f\"{'Avg. FPS':<15} | {kcf_fps:<20.2f} | {csrt_fps:<20.2f} |\")\n",
    "        \n",
    "        kcf_fail = results.get(\"kcf\", {}).get(\"failures\", 0)\n",
    "        csrt_fail = results.get(\"csrt\", {}).get(\"failures\", 0)\n",
    "        print(f\"{'Total Failures':<15} | {kcf_fail:<20} | {csrt_fail:<20} |\")\n",
    "\n",
    "        kcf_rate = results.get(\"kcf\", {}).get(\"success_rate\", 0)\n",
    "        csrt_rate = results.get(\"csrt\", {}).get(\"success_rate\", 0)\n",
    "        print(f\"{'Success Rate':<15} | {kcf_rate:<19.2f}% | {csrt_rate:<19.2f}% |\")\n",
    "\n",
    "    else:\n",
    "        print(\"No tracking sessions were completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd7861",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "## **Tracker Architecture Comparison**\n",
    "\n",
    "### **KCF**\n",
    "- Operates in the Fourier domain, enabling fast correlation computations using FFT.  \n",
    "- Uses kernel tricks to build a non-linear classifier that separates the object from the background.  \n",
    "- Learns a correlation filter from the target’s appearance and applies it frame-by-frame to locate the object.  \n",
    "- Prioritizes speed and efficiency but struggles with large appearance changes or occlusions.\n",
    "\n",
    "### **CSRT**\n",
    "- A more advanced discriminative correlation filter tracker.  \n",
    "- Uses spatial reliability maps and multiple feature channels (color, gradient, etc.).  \n",
    "- Assigns reliability weights to different regions and channels, improving robustness to occlusion and appearance changes.  \n",
    "- Focuses on accuracy and stability at the cost of speed.\n",
    "\n",
    "### **Performance Analysis**\n",
    "\n",
    "### **1. Tracking Speed (FPS)**\n",
    "\n",
    "| Tracker | FPS | Relative Speed |\n",
    "|----------|-----|----------------|\n",
    "| KCF | 23.62 | — |\n",
    "| CSRT | 7.09 | **3.3× slower** |\n",
    "\n",
    "- **KCF** achieves higher speed through **FFT-based computation**, ideal for **real-time tracking**.  \n",
    "- **CSRT**’s multi-channel analysis and reliability computation increase accuracy but **reduce frame rate**.\n",
    "\n",
    "### **2. Tracking Robustness**\n",
    "\n",
    "| Metric | KCF | CSRT |\n",
    "|---------|-----|------|\n",
    "| Success Rate | 100% | 100% |\n",
    "| Stability | Slight jitter during movement | Smoother, more precise tracking |\n",
    "\n",
    "- Both trackers succeeded in this controlled video, indicating **favorable conditions** (no major occlusions or drastic changes).  \n",
    "- **KCF:** Minor jitter and drift during rapid motion or lighting changes.  \n",
    "- **CSRT:** Maintained tighter bounding box alignment and smoother tracking throughout.\n",
    "\n",
    "### **3. Failure Cases and Limitations**\n",
    "\n",
    "#### **KCF Weaknesses**\n",
    "- **Scale Variation:** Fixed-size filter → poor adaptability to large scale changes.  \n",
    "- **Appearance Changes:** Sensitive to rotation and pose variations.  \n",
    "- **Occlusion:** Limited robustness to partial or full occlusions.  \n",
    "- **Background Clutter:** May drift if background patterns resemble the target.\n",
    "\n",
    "#### **CSRT Weaknesses**\n",
    "- **Computational Cost:** Slower due to feature weighting and spatial reliability mapping.  \n",
    "- **Complete Occlusions:** More robust than KCF but still prone to long-term failures.  \n",
    "- **Initialization Sensitivity:** Requires precise initial bounding box for accurate tracking.\n",
    "\n",
    "### **Key Trade-offs** (For the tested video)\n",
    "\n",
    "| Aspect | KCF | CSRT |\n",
    "|--------|-----|------|\n",
    "| Speed | Faster (23.6 FPS) | Slower (7.1 FPS) |\n",
    "| Accuracy | Moderate | High |\n",
    "| Occlusion Handling | Weak | Stronger |\n",
    "| Adaptability | Limited | Better (spatial reliability) |\n",
    "| Resource Efficiency | Lightweight | Computationally heavy |\n",
    "\n",
    "### **Comparison with Modern Deep Learning Trackers**\n",
    "\n",
    "| Aspect | Classical Trackers (KCF/CSRT) | Deep Trackers (e.g., SiamFC, DiMP, ATOM) |\n",
    "|---------|-------------------------------|-------------------------------------------|\n",
    "| Appearance Adaptation | Limited | Excellent |\n",
    "| Occlusion Handling | Moderate | Strong |\n",
    "| Scale Handling | Weak (KCF) / Moderate (CSRT) | Robust |\n",
    "| Resource Requirement | Low | High (GPU, training data) |\n",
    "| Ease of Use | Plug-and-play | Requires training & dependencies |\n",
    "\n",
    "- Deep trackers provide **superior accuracy and robustness** but require GPUs and pre-trained models.  \n",
    "- Classical trackers remain **relevant for lightweight, quick deployment**—especially when training data or high-end hardware is unavailable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
